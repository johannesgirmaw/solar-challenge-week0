{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db484c27",
   "metadata": {},
   "source": [
    "Perform Exploratory Data Analysis (EDA) analysis on the following:\n",
    "\n",
    "- Summary Statistics & Missing-Value Report\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27854fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47650ef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.inspect_data import inspect_data\n",
    "from scripts.clean_data import clean_data\n",
    "from scripts.read_file import read_csv_file\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5934dd8f",
   "metadata": {},
   "source": [
    "Reading csv data using pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90b84ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/benin-malanville.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8cc81d",
   "metadata": {},
   "source": [
    "Summary Statistics & Missing-Value Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa69e27d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Descriptive Statistics for Numeric Columns ---\n",
      "                 GHI            DNI            DHI           ModA  \\\n",
      "count  525600.000000  525600.000000  525600.000000  525600.000000   \n",
      "mean      240.559452     167.187516     115.358961     236.589496   \n",
      "std       331.131327     261.710501     158.691074     326.894859   \n",
      "min       -12.900000      -7.800000     -12.600000       0.000000   \n",
      "25%        -2.000000      -0.500000      -2.100000       0.000000   \n",
      "50%         1.800000      -0.100000       1.600000       4.500000   \n",
      "75%       483.400000     314.200000     216.300000     463.700000   \n",
      "max      1413.000000     952.300000     759.200000    1342.300000   \n",
      "\n",
      "                ModB           Tamb             RH             WS  \\\n",
      "count  525600.000000  525600.000000  525600.000000  525600.000000   \n",
      "mean      228.883576      28.179683      54.487969       2.121113   \n",
      "std       316.536515       5.924297      28.073069       1.603466   \n",
      "min         0.000000      11.000000       2.100000       0.000000   \n",
      "25%         0.000000      24.200000      28.800000       1.000000   \n",
      "50%         4.300000      28.000000      55.100000       1.900000   \n",
      "75%       447.900000      32.300000      80.100000       3.100000   \n",
      "max      1342.300000      43.800000     100.000000      19.500000   \n",
      "\n",
      "              WSgust        WSstdev             WD        WDstdev  \\\n",
      "count  525600.000000  525600.000000  525600.000000  525600.000000   \n",
      "mean        2.809195       0.473390     153.435172       8.582407   \n",
      "std         2.029120       0.273395     102.332842       6.385864   \n",
      "min         0.000000       0.000000       0.000000       0.000000   \n",
      "25%         1.300000       0.400000      59.000000       3.700000   \n",
      "50%         2.600000       0.500000     181.000000       8.600000   \n",
      "75%         4.100000       0.600000     235.100000      12.300000   \n",
      "max        26.600000       4.200000     360.000000      99.400000   \n",
      "\n",
      "                  BP       Cleaning  Precipitation          TModA  \\\n",
      "count  525600.000000  525600.000000  525600.000000  525600.000000   \n",
      "mean      994.197199       0.000923       0.001905      35.246026   \n",
      "std         2.474993       0.030363       0.037115      14.807258   \n",
      "min       985.000000       0.000000       0.000000       9.000000   \n",
      "25%       993.000000       0.000000       0.000000      24.200000   \n",
      "50%       994.000000       0.000000       0.000000      30.000000   \n",
      "75%       996.000000       0.000000       0.000000      46.900000   \n",
      "max      1003.000000       1.000000       2.500000      81.000000   \n",
      "\n",
      "               TModB  Comments  \n",
      "count  525600.000000       0.0  \n",
      "mean       32.471736       NaN  \n",
      "std        12.348743       NaN  \n",
      "min         8.100000       NaN  \n",
      "25%        23.600000       NaN  \n",
      "50%        28.900000       NaN  \n",
      "75%        41.500000       NaN  \n",
      "max        72.500000       NaN  \n",
      "\n",
      "--- Missing Value Counts per Column ---\n",
      "Timestamp             0\n",
      "GHI                   0\n",
      "DNI                   0\n",
      "DHI                   0\n",
      "ModA                  0\n",
      "ModB                  0\n",
      "Tamb                  0\n",
      "RH                    0\n",
      "WS                    0\n",
      "WSgust                0\n",
      "WSstdev               0\n",
      "WD                    0\n",
      "WDstdev               0\n",
      "BP                    0\n",
      "Cleaning              0\n",
      "Precipitation         0\n",
      "TModA                 0\n",
      "TModB                 0\n",
      "Comments         525600\n",
      "dtype: int64\n",
      "\n",
      "--- Columns with > 5% Missing Values ---\n",
      "['Comments']\n"
     ]
    }
   ],
   "source": [
    "# 1. Describe all numeric columns\n",
    "print(\"--- Descriptive Statistics for Numeric Columns ---\")\n",
    "print(df.describe())\n",
    "\n",
    "# 2. Calculate the number of missing values per column\n",
    "print(\"\\n--- Missing Value Counts per Column ---\")\n",
    "missing_counts = df.isna().sum()\n",
    "print(missing_counts)\n",
    "\n",
    "# 3. Identify columns with > 5% nulls\n",
    "total_rows = len(df)\n",
    "null_percentage_threshold = 0.05  # 5%\n",
    "\n",
    "columns_with_high_nulls = missing_counts[missing_counts /\n",
    "                                            total_rows > null_percentage_threshold].index.tolist()\n",
    "\n",
    "print(\"\\n--- Columns with > 5% Missing Values ---\")\n",
    "if columns_with_high_nulls:\n",
    "    print(columns_with_high_nulls)\n",
    "else:\n",
    "    print(\"No columns have more than 5% missing values.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "645295fe",
   "metadata": {},
   "source": [
    "Outlier Detection & Basic Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74c4a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Looks for missing values, potential outliers, and basic statistics\n",
    "for the specified columns in the DataFrame.\n",
    "\n",
    "Args:\n",
    "    df (pd.DataFrame): The input DataFrame.\n",
    "    columns_to_inspect (list): A list of column names to inspect.\n",
    "\"\"\"\n",
    "columns_to_inspect = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust']\n",
    "for col in columns_to_inspect:\n",
    "    print(f\"\\n--- Column: {col} ---\")\n",
    "\n",
    "    # 1. Missing Values\n",
    "    missing_count = df[col].isnull().sum()\n",
    "    missing_percentage = (missing_count / len(df)) * 100\n",
    "    print(f\"Missing Value Count: {missing_count}\")\n",
    "    print(f\"Missing Value Percentage: {missing_percentage:.2f}%\")\n",
    "\n",
    "    # 2. Basic Statistics\n",
    "    print(\"\\n--- Basic Statistics ---\")\n",
    "    print(df[col].describe())\n",
    "\n",
    "    # 3. Outlier Detection (using IQR and Visualization)\n",
    "    print(\"\\n--- Outlier Detection (IQR) ---\")\n",
    "    Q1 = df[col].quantile(0.25)\n",
    "    Q3 = df[col].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    lower_bound = Q1 - 1.5 * IQR\n",
    "    upper_bound = Q3 + 1.5 * IQR\n",
    "    outliers_iqr = df[(df[col] < lower_bound) | (df[col] > upper_bound)]\n",
    "    print(f\"Number of potential outliers (IQR): {len(outliers_iqr)}\")\n",
    "    if not outliers_iqr.empty:\n",
    "        print(f\"Example outlier values:\\n{outliers_iqr[col].head()}\")\n",
    "\n",
    "    # 4. Visualization (Box Plot for Outliers)\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(x=df[col])\n",
    "    plt.title(f\"Box Plot of {col}\")\n",
    "    plt.xlabel(col)\n",
    "    plt.show()\n",
    "\n",
    "    # 5. Potential Incorrect Entries (based on domain knowledge - adjust as needed)\n",
    "    print(\"\\n--- Potential Incorrect Entries ---\")\n",
    "    if col in ['GHI', 'DNI', 'DHI', 'ModA', 'ModB']:\n",
    "        # Allowing a small negative due to potential sensor noise\n",
    "        negative_values = df[df[col] < -5][col]\n",
    "        if not negative_values.empty:\n",
    "            print(\n",
    "                f\"Number of potentially incorrect (significantly negative) values: {len(negative_values)}\")\n",
    "            print(f\"Example negative values:\\n{negative_values.head()}\")\n",
    "        else:\n",
    "            print(\"No significantly negative values found.\")\n",
    "    elif col in ['WS', 'WSgust']:\n",
    "        # Wind speed should generally be non-negative\n",
    "        negative_ws = df[df[col] < 0][col]\n",
    "        if not negative_ws.empty:\n",
    "            print(\n",
    "                f\"Number of potentially incorrect (negative) wind speed values: {len(negative_ws)}\")\n",
    "            print(\n",
    "                f\"Example negative wind speed values:\\n{negative_ws.head()}\")\n",
    "        else:\n",
    "            print(\"No negative wind speed values found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5994d0",
   "metadata": {},
   "source": [
    "    Computes Z-scores for specified columns and flags rows where the absolute\n",
    "    Z-score is greater than 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "320a5409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          Timestamp  GHI  DNI  DHI  ModA  ModB   WS  WSgust  is_zscore_outlier\n",
      "0  2021-08-09 00:01 -1.2 -0.2 -1.1   0.0   0.0  0.0     0.4              False\n",
      "1  2021-08-09 00:02 -1.1 -0.2 -1.1   0.0   0.0  0.0     0.0              False\n",
      "2  2021-08-09 00:03 -1.1 -0.2 -1.1   0.0   0.0  0.3     1.1              False\n",
      "3  2021-08-09 00:04 -1.1 -0.1 -1.0   0.0   0.0  0.2     0.7              False\n",
      "4  2021-08-09 00:05 -1.0 -0.1 -1.0   0.0   0.0  0.1     0.7              False\n",
      "\n",
      "Number of rows flagged as Z-score outliers (|Z| > 3): 7740\n"
     ]
    }
   ],
   "source": [
    "def flag_zscore_outliers(df, columns):\n",
    "    \"\"\"\n",
    "    Computes Z-scores for specified columns and flags rows where the absolute\n",
    "    Z-score is greater than 3.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        columns (list): A list of column names to compute Z-scores for.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with a new boolean column 'is_zscore_outlier'\n",
    "                      indicating if any of the specified columns have a |Z|>3.\n",
    "    \"\"\"\n",
    "    df['is_zscore_outlier'] = False  # Initialize the flag column\n",
    "\n",
    "    for col in columns:\n",
    "        if col in df.columns and pd.api.types.is_numeric_dtype(df[col]):\n",
    "            # Calculate Z-scores, handling potential NaN values\n",
    "            z_scores = np.abs(stats.zscore(df[col], nan_policy='omit'))\n",
    "\n",
    "            # Flag rows where the absolute Z-score is greater than 3 for the current column\n",
    "            outlier_mask = z_scores > 3\n",
    "            df.loc[outlier_mask, 'is_zscore_outlier'] = True\n",
    "        else:\n",
    "            print(\n",
    "                f\"Warning: Column '{col}' not found or is not numeric. Skipping Z-score calculation.\")\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Specify the columns for Z-score calculation\n",
    "zscore_columns = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust']\n",
    "\n",
    "# Assuming your DataFrame is named 'df'\n",
    "df_with_zscore_flags = flag_zscore_outliers(df.copy(), zscore_columns)\n",
    "\n",
    "# Display the first few rows with the outlier flag\n",
    "print(df_with_zscore_flags[['Timestamp'] +\n",
    "      zscore_columns + ['is_zscore_outlier']].head())\n",
    "\n",
    "# You can also see how many outliers were flagged:\n",
    "num_zscore_outliers = df_with_zscore_flags['is_zscore_outlier'].sum()\n",
    "print(\n",
    "    f\"\\nNumber of rows flagged as Z-score outliers (|Z| > 3): {num_zscore_outliers}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20f700ce",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "058b14b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Handling Missing Values in Columns: ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust'] ---\n",
      "Initial number of rows: 525600\n",
      "\n",
      "Missing values before handling:\n",
      "GHI       0\n",
      "DNI       0\n",
      "DHI       0\n",
      "ModA      0\n",
      "ModB      0\n",
      "WS        0\n",
      "WSgust    0\n",
      "dtype: int64\n",
      "Dropped 0 rows with missing values in column 'GHI'.\n",
      "Dropped 0 rows with missing values in column 'DNI'.\n",
      "Dropped 0 rows with missing values in column 'DHI'.\n",
      "Dropped 0 rows with missing values in column 'ModA'.\n",
      "Dropped 0 rows with missing values in column 'ModB'.\n",
      "Dropped 0 rows with missing values in column 'WS'.\n",
      "Dropped 0 rows with missing values in column 'WSgust'.\n",
      "\n",
      "Number of rows after handling missing values: 525600\n",
      "\n",
      "Missing values after handling:\n",
      "GHI       0\n",
      "DNI       0\n",
      "DHI       0\n",
      "ModA      0\n",
      "ModB      0\n",
      "WS        0\n",
      "WSgust    0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame after dropping missing values:\n",
      "   GHI  DNI  DHI  ModA  ModB   WS  WSgust\n",
      "0 -1.2 -0.2 -1.1   0.0   0.0  0.0     0.4\n",
      "1 -1.1 -0.2 -1.1   0.0   0.0  0.0     0.0\n",
      "2 -1.1 -0.2 -1.1   0.0   0.0  0.3     1.1\n",
      "3 -1.1 -0.1 -1.0   0.0   0.0  0.2     0.7\n",
      "4 -1.0 -0.1 -1.0   0.0   0.0  0.1     0.7\n",
      "--- Handling Missing Values in Columns: ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust'] ---\n",
      "Initial number of rows: 525600\n",
      "\n",
      "Missing values before handling:\n",
      "GHI       0\n",
      "DNI       0\n",
      "DHI       0\n",
      "ModA      0\n",
      "ModB      0\n",
      "WS        0\n",
      "WSgust    0\n",
      "dtype: int64\n",
      "Imputed missing values in column 'GHI' with median: 1.80\n",
      "Imputed missing values in column 'DNI' with median: -0.10\n",
      "Imputed missing values in column 'DHI' with median: 1.60\n",
      "Imputed missing values in column 'ModA' with median: 4.50\n",
      "Imputed missing values in column 'ModB' with median: 4.30\n",
      "Imputed missing values in column 'WS' with median: 1.90\n",
      "Imputed missing values in column 'WSgust' with median: 2.60\n",
      "\n",
      "Number of rows after handling missing values: 525600\n",
      "\n",
      "Missing values after handling:\n",
      "GHI       0\n",
      "DNI       0\n",
      "DHI       0\n",
      "ModA      0\n",
      "ModB      0\n",
      "WS        0\n",
      "WSgust    0\n",
      "dtype: int64\n",
      "\n",
      "DataFrame after imputing missing values with median:\n",
      "   GHI  DNI  DHI  ModA  ModB   WS  WSgust\n",
      "0 -1.2 -0.2 -1.1   0.0   0.0  0.0     0.4\n",
      "1 -1.1 -0.2 -1.1   0.0   0.0  0.0     0.0\n",
      "2 -1.1 -0.2 -1.1   0.0   0.0  0.3     1.1\n",
      "3 -1.1 -0.1 -1.0   0.0   0.0  0.2     0.7\n",
      "4 -1.0 -0.1 -1.0   0.0   0.0  0.1     0.7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_131130/2226578486.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_handled[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_131130/2226578486.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_handled[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_131130/2226578486.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_handled[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_131130/2226578486.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_handled[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_131130/2226578486.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_handled[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_131130/2226578486.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_handled[col].fillna(median_val, inplace=True)\n",
      "/tmp/ipykernel_131130/2226578486.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df_handled[col].fillna(median_val, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "def handle_missing_values(df, key_columns, imputation_strategy='median'):\n",
    "    \"\"\"\n",
    "    Drops rows with missing values or imputes them using the median\n",
    "    for the specified key columns.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The input DataFrame.\n",
    "        key_columns (list): A list of column names where missing values should be handled.\n",
    "        imputation_strategy (str, optional): Strategy for handling missing values.\n",
    "                                             'drop' to remove rows with any missing value in key columns.\n",
    "                                             'median' to impute missing values with the median of the column.\n",
    "                                             Defaults to 'median'.\n",
    "\n",
    "    Returns:\n",
    "        pd.DataFrame: The DataFrame with missing values handled in the key columns.\n",
    "    \"\"\"\n",
    "    df_handled = df.copy()  # Work on a copy\n",
    "\n",
    "    print(f\"--- Handling Missing Values in Columns: {key_columns} ---\")\n",
    "    print(f\"Initial number of rows: {len(df_handled)}\")\n",
    "    print(\"\\nMissing values before handling:\")\n",
    "    print(df_handled[key_columns].isnull().sum())\n",
    "\n",
    "    for col in key_columns:\n",
    "        if col in df_handled.columns:\n",
    "            if imputation_strategy.lower() == 'drop':\n",
    "                initial_rows = len(df_handled)\n",
    "                df_handled.dropna(subset=[col], inplace=True)\n",
    "                rows_dropped = initial_rows - len(df_handled)\n",
    "                print(\n",
    "                    f\"Dropped {rows_dropped} rows with missing values in column '{col}'.\")\n",
    "            elif imputation_strategy.lower() == 'median':\n",
    "                median_val = df_handled[col].median()\n",
    "                df_handled[col].fillna(median_val, inplace=True)\n",
    "                print(\n",
    "                    f\"Imputed missing values in column '{col}' with median: {median_val:.2f}\")\n",
    "            else:\n",
    "                print(\n",
    "                    f\"Warning: Unknown imputation strategy '{imputation_strategy}'. Skipping column '{col}'.\")\n",
    "        else:\n",
    "            print(f\"Warning: Key column '{col}' not found in DataFrame.\")\n",
    "\n",
    "    print(f\"\\nNumber of rows after handling missing values: {len(df_handled)}\")\n",
    "    print(\"\\nMissing values after handling:\")\n",
    "    print(df_handled[key_columns].isnull().sum())\n",
    "\n",
    "    return df_handled\n",
    "\n",
    "\n",
    "# Specify the key columns where you want to handle missing values\n",
    "key_columns_to_handle = ['GHI', 'DNI', 'DHI', 'ModA', 'ModB', 'WS', 'WSgust']\n",
    "\n",
    "# Assuming your DataFrame is named 'df'\n",
    "\n",
    "# Option 1: Drop rows with missing values in key columns\n",
    "df_dropped_na = handle_missing_values(\n",
    "    df.copy(), key_columns_to_handle, imputation_strategy='drop')\n",
    "print(\"\\nDataFrame after dropping missing values:\")\n",
    "print(df_dropped_na[key_columns_to_handle].head())\n",
    "\n",
    "# Option 2: Impute missing values with the median in key columns\n",
    "df_imputed_median = handle_missing_values(\n",
    "    df.copy(), key_columns_to_handle, imputation_strategy='median')\n",
    "print(\"\\nDataFrame after imputing missing values with median:\")\n",
    "print(df_imputed_median[key_columns_to_handle].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186816ef",
   "metadata": {},
   "source": [
    "    Exports the cleaned DataFrame to a CSV file in the specified directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e9dc6823",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cleaned DataFrame for benin exported to: data/benin_clean.csv\n",
      "Ensure the 'data/' directory is in your .gitignore file to avoid committing CSVs.\n"
     ]
    }
   ],
   "source": [
    "def export_cleaned_data(df, country_name, output_dir='data'):\n",
    "    \"\"\"\n",
    "    Exports the cleaned DataFrame to a CSV file in the specified directory.\n",
    "    Args:\n",
    "        df (pd.DataFrame): The cleaned DataFrame to export.\n",
    "        country_name (str): The name of the country (used in the filename).\n",
    "        output_dir (str, optional): The directory to save the CSV file.\n",
    "                                     Defaults to 'data'.\n",
    "    \"\"\"\n",
    "    # Ensure the output directory exists\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "    # Create the filename\n",
    "    filename = f\"{country_name}_clean.csv\"\n",
    "    filepath = os.path.join(output_dir, filename)\n",
    "\n",
    "    # Export the DataFrame to CSV\n",
    "    # index=False prevents writing the DataFrame index to the CSV\n",
    "    df.to_csv(filepath, index=False)\n",
    "\n",
    "    print(f\"Cleaned DataFrame for {country_name} exported to: {filepath}\")\n",
    "    print(\n",
    "        f\"Ensure the '{output_dir}/' directory is in your .gitignore file to avoid committing CSVs.\")\n",
    "\n",
    "\n",
    "# Example Usage:\n",
    "# Assuming you have a cleaned DataFrame named 'df_cleaned' and the country is 'benin'\n",
    "country = \"benin\"\n",
    "cleaned_df = df.copy()  # Replace with your actual cleaned DataFrame\n",
    "\n",
    "export_cleaned_data(cleaned_df, country)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
